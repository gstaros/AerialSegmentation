{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "import torch\n",
        "import torchvision.transforms.v2 as T\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "\n",
        "from src.data.dataset import ImageSegmentationDataset\n",
        "from src.models.load_model import load_model\n",
        "from src.utils.utils import one_hot_decoding\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "##### LOAD CONFIGS #####\n",
        "with open('src/config/interference_config.yml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "with open('src/config/config.yml', 'r') as file:\n",
        "    model_config = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "\n",
        "##### PARAMETERS #####\n",
        "MODEL_SELECTION = config['MODEL_SELECTION']\n",
        "\n",
        "IMAGE_SIZE = model_config['IMAGE_SIZE']\n",
        "INPUT_CHANNELS = model_config['INPUT_CHANNELS']\n",
        "OUTPUT_CHANNELS = model_config['OUTPUT_CHANNELS']\n",
        "\n",
        "BATCH_SIZE = config['BATCH_SIZE']\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize([IMAGE_SIZE, IMAGE_SIZE], interpolation=T.InterpolationMode.NEAREST)\n",
        "])\n",
        "\n",
        "\n",
        "test_dataset = ImageSegmentationDataset(\n",
        "    dir_file= config['TEST_CSV'],\n",
        "    n_channels = INPUT_CHANNELS,\n",
        "    n_classes = OUTPUT_CHANNELS,\n",
        "    transform = transform # add more transform functions\n",
        ")\n",
        "\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Showing Images and Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "flair_data = {\n",
        "    0   : ['building','#db0e9a'] ,\n",
        "    1   : ['pervious surface','#938e7b'],\n",
        "    2   : ['impervious surface','#f80c00'],\n",
        "    3   : ['bare soil','#a97101'],\n",
        "    4   : ['water','#1553ae'],\n",
        "    5   : ['coniferous','#194a26'],\n",
        "    6   : ['deciduous','#46e483'],\n",
        "    7   : ['brushwood','#f3a60d'],\n",
        "    8   : ['vineyard','#660082'],\n",
        "    9   : ['herbaceous vegetation','#55ff00'],\n",
        "    10  : ['agricultural land','#fff30d'],\n",
        "    11  : ['plowed land','#e4df7c'],\n",
        "    12  : ['other','#3de6eb'],\n",
        "}\n",
        "\n",
        "labels = [flair_data[x][0] for x in flair_data]\n",
        "colormap =  [flair_data[x][1] for x in flair_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images(images):\n",
        "  fig, axis = plt.subplots(1, len(images), figsize=(len(images) * 4, len(images) * 5))\n",
        "\n",
        "  for idx, image in enumerate(images):\n",
        "    image = image.type(torch.uint8)\n",
        "    if len(image.shape) == 2:\n",
        "      image = image.unsqueeze(dim=0)\n",
        "\n",
        "    image = axis[idx].imshow(image.permute(1, 2, 0))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_mask_visual(mask, colormap, n_colors=13):\n",
        "\n",
        "    mask = mask.type(torch.uint8)\n",
        "    if len(mask.shape) == 2:\n",
        "      mask = mask.unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "    # Define the colors (13 distinct colors)\n",
        "    cmap = mcolors.ListedColormap(colormap)\n",
        "\n",
        "    # Normalize the colormap\n",
        "    bounds = np.arange(-0.5, n_colors, 1)\n",
        "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    return mask, cmap, norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_mask(mask, colormap, labels, n_colors=13):\n",
        "\n",
        "    mask, cmap, norm = prepare_mask_visual(mask, colormap, n_colors)\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots()\n",
        "    mask = ax.imshow(mask.permute(1, 2, 0), cmap=cmap, norm=norm, interpolation='nearest')\n",
        "\n",
        "    # Optional: Add color bar with appropriate ticks\n",
        "    cbar = fig.colorbar(mask, ticks=np.arange(0, n_colors))\n",
        "    cbar.ax.set_yticklabels(labels)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images_and_masks(images, masks, n_colors=13, compare=False):\n",
        "  im_len = len(images) + len(masks)\n",
        "  fig, axis = plt.subplots(1, im_len, figsize=(im_len * 4, im_len * 5))\n",
        "\n",
        "  for idx, image in enumerate(images):\n",
        "    image = image.type(torch.uint8)\n",
        "    if len(image.shape) == 2:\n",
        "      image = image.unsqueeze(dim=0)\n",
        "\n",
        "    image = axis[idx].imshow(image.permute(1, 2, 0))\n",
        "\n",
        "  for idx, mask in enumerate(masks):\n",
        "    mask = mask.type(torch.uint8)\n",
        "    if len(mask.shape) == 2:\n",
        "      mask = mask.unsqueeze(dim=0)\n",
        "\n",
        "    mask, cmap, norm = prepare_mask_visual(mask, colormap, n_colors)\n",
        "\n",
        "    mask = axis[idx + len(images)].imshow(mask.permute(1, 2, 0), cmap=cmap, norm=norm, interpolation='nearest')\n",
        "\n",
        "  if compare and len(masks) == 2:\n",
        "    # iou_metric = MulticlassJaccardIndex(n_colors)\n",
        "    # iou = iou_metric(masks[0], masks[1])\n",
        "\n",
        "    compared_masks = masks[0] == masks[1]\n",
        "    similarity = (compared_masks.sum() / masks[0].numel()).item() * 100\n",
        "\n",
        "    axis[im_len - 2].set_title(f'Ground truth')\n",
        "    \n",
        "    axis[im_len - 1].set_title(f'PixelAccuracy: {similarity:.2f}%')\n",
        "    # axis[im_len - 1].set_title(f'PixelAccuracy: {similarity:.2f}%\\nmIoU: {iou:.4f}')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    image, mask  = random.choice(test_dataset)\n",
        "    \n",
        "    image_rgb = image[:3, :, :]\n",
        "    image_nir = image[3, :, :]\n",
        "    image_el = image[4, :, :]\n",
        "\n",
        "    show_images_and_masks([image_rgb, image_nir, image_el], [mask], OUTPUT_CHANNELS)\n",
        "    show_mask(mask, colormap, labels, OUTPUT_CHANNELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Models list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_name_list = ['UNet', 'UNet++', 'ViTSegmenter', 'ResViTSegmenter']\n",
        "\n",
        "models_list = []\n",
        "for model_name in models_name_list:\n",
        "\n",
        "    model = load_model(model_name, model_config)\n",
        "    checkpoint = torch.load(model_config['MODEL'][model_name]['ckp'])\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f'Model: {model_name} loaded')\n",
        "\n",
        "    models_list.append(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_photos = 20\n",
        "\n",
        "for photo_idx in range(num_photos):\n",
        "\n",
        "    # Create a figure and a gridspec layout\n",
        "    fig, axes = plt.subplots(1, len(models_name_list) + 3, figsize=(17, 3), gridspec_kw={'width_ratios': [1, 1, 1, 1, 1, 1, 0.4]})\n",
        "\n",
        "    # Choose random photo\n",
        "    satellite_photo = random.choice(test_dataset)\n",
        "\n",
        "    # Set RGB and ground truth \n",
        "    rgb = satellite_photo[0][:3].type(torch.uint8)\n",
        "    ground_truth = satellite_photo[1].unsqueeze(0)\n",
        "\n",
        "    # Display RGB image\n",
        "    axes[0].imshow(rgb.permute(1, 2, 0))\n",
        "    axes[0].set_title(\"RGB\")\n",
        "    \n",
        "    # Prepare and display the ground truth\n",
        "    ground_truth, cmap, norm = prepare_mask_visual(ground_truth, colormap, len(flair_data))\n",
        "    ground_truth_im = axes[1].imshow(ground_truth.permute(1, 2, 0), cmap=cmap, norm=norm, interpolation='nearest')\n",
        "    axes[1].set_title(\"Ground Truth\")\n",
        "\n",
        "    # Remove axis ticks from the first two plots\n",
        "    for ax in axes[:2]:\n",
        "        ax.get_xaxis().set_ticks([])\n",
        "        ax.get_yaxis().set_ticks([])\n",
        "\n",
        "    # Loop through models and display predictions\n",
        "    for idx, model in enumerate(models_list, 2):\n",
        "        model.eval()\n",
        "        model_pred = model(satellite_photo[0].unsqueeze(0))\n",
        "        model_pred_mask = one_hot_decoding(model_pred, dim=1)\n",
        "        \n",
        "        axes[idx].imshow(model_pred_mask.permute(1, 2, 0), cmap=cmap, norm=norm, interpolation='nearest')\n",
        "        axes[idx].set_title(models_name_list[idx - 2])\n",
        "        axes[idx].get_xaxis().set_ticks([])\n",
        "        axes[idx].get_yaxis().set_ticks([])\n",
        "\n",
        "    # Turn off the axis for the colorbar subplot\n",
        "    axes[len(models_name_list) + 2].axis('off')\n",
        "\n",
        "    # Add the colorbar to the last (narrow) subplot\n",
        "    cbar = fig.colorbar(ground_truth_im, ax=axes[len(models_name_list) + 2], ticks=np.arange(0, len(flair_data)))\n",
        "    cbar.ax.set_yticklabels(labels)\n",
        "\n",
        "    # Adjust layout to remove extra whitespace\n",
        "    plt.subplots_adjust(wspace=0.05)  # Decrease horizontal spacing\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
